{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOUnCaY1cjadDPoUB4ww82",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jhonald73/TPproj_github/blob/main/W2S2_Activities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "# Load key from Google Colab Secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=api_key,\n",
        ")"
      ],
      "metadata": {
        "id": "Eb2TU_2OdqLr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDVt9kkIde3T",
        "outputId": "7b427185-65a4-448f-a70e-113d4b09f8cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Automated Data Prep/laptop_prices_2024_sgd_TL.csv\")"
      ],
      "metadata": {
        "id": "H4RJ9Uj4d27Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the first few rows to a string to send to OpenAI\n",
        "data_preview = df.head(10).to_csv(index=False)\n",
        "print(data_preview)\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    instructions=\"You are an expert data scientist with extensive knowledge of predictive analysis and linear regression.\",\n",
        "    input=f\"Dataset: laptop_prices_2024_sgd_TL (150 samples, 4 features, 3 classes)\\nHere are the first 10 rows of the dataset:\\n{data_preview}]\",\n",
        ")\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2hDCB3LeiD_",
        "outputId": "271a6265-b4d7-4bfe-fda0-65674063e552"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brand,Model,CPU,GPU,RAM_GB,Storage_Type,Storage_GB,Touchscreen,Weight_kg,Screen_Size_inch,Discount_percent,Price_SGD,Brand_Discount,Member_Discount\n",
            "Acer,Aspire 5,Intel i9-14900HK,NVIDIA RTX 4070,64,SSD,256,False,1.56,16.0,3.27,2413.36,5,144.8\n",
            "Acer,Nitro 5,AMD Ryzen 9 8900HX,AMD Radeon 780M,32,SSD,1024,True,1.45,14.0,5.03,1773.75,5,124.16\n",
            "Acer,Nitro 5,AMD Ryzen 5 8600H,NVIDIA RTX 4050,32,SSD,2048,False,1.34,14.0,4.41,1634.07,5,98.04\n",
            "Acer,TravelMate P6,Intel Core Ultra 7 15500H,NVIDIA RTX 4060,16,SSD,4096,True,1.18,13.3,2.16,2362.59,5,118.13\n",
            "Acer,Predator Helios 300,Intel i7-14800H,NVIDIA RTX 4070,8,SSD,1024,True,1.31,14.0,6.93,2218.55,5,155.3\n",
            "Acer,Aspire 5,Intel i9-14900HK,NVIDIA RTX 4080,32,SSD,256,False,3.34,17.3,8.94,2224.12,5,155.69\n",
            "Acer,TravelMate P6,Intel i9-14900HK,NVIDIA RTX 4080,128,SSD,1024,True,1.11,13.3,11.72,3016.36,5,211.15\n",
            "Acer,Predator Helios 300,Intel Core Ultra 9 15700H,NVIDIA RTX 4070,16,SSD,2048,True,1.29,13.3,8.84,2579.29,5,180.55\n",
            "Acer,Swift 3,Intel i5-14500H,NVIDIA RTX 4050,64,SSD,4096,False,1.4,13.3,6.92,1976.94,5,98.85\n",
            "Acer,Nitro 5,Intel Core Ultra 9 15700H,NVIDIA RTX 4070,16,SSD,2048,False,1.15,13.3,5.25,2538.34,5,152.3\n",
            "\n",
            "Based on the dataset provided, let's explore key aspects for predictive analysis and linear regression. You have several features related to laptop specifications and pricing that can be useful for modeling.\n",
            "\n",
            "### Features Overview\n",
            "1. **Brand**\n",
            "2. **Model**\n",
            "3. **CPU** \n",
            "4. **GPU** \n",
            "5. **RAM_GB** \n",
            "6. **Storage_Type** \n",
            "7. **Storage_GB** \n",
            "8. **Touchscreen** (boolean)\n",
            "9. **Weight_kg** \n",
            "10. **Screen_Size_inch** \n",
            "11. **Discount_percent** \n",
            "12. **Price_SGD** \n",
            "13. **Brand_Discount** \n",
            "14. **Member_Discount**\n",
            "\n",
            "### Steps for Analysis\n",
            "\n",
            "1. **Data Preprocessing:**\n",
            "   - **Encoding Categorical Variables:** Convert categorical features like `Brand`, `Model`, `CPU`, `GPU`, and `Storage_Type` into numerical form using techniques like one-hot encoding or label encoding.\n",
            "   - **Handling Missing Values:** Check for any missing values and decide how to handle them (e.g., imputation, removal).\n",
            "   - **Normalizing/Standardizing Numerical Features:** Apply scaling to the features, especially those that vary in magnitude, such as `Weight_kg`, `Screen_Size_inch`, and `Price_SGD`.\n",
            "\n",
            "2. **Exploratory Data Analysis (EDA):**\n",
            "   - **Correlation Analysis:** Use correlation matrices to understand relationships between features and the target variable (`Price_SGD`).\n",
            "   - **Visualizations:** Create scatter plots, box plots, and histograms to visualize the distribution of laptop prices and other features.\n",
            "\n",
            "3. **Feature Selection:**\n",
            "   - Assess which features are most influential for predicting laptop prices. This may involve using techniques such as recursive feature elimination or considering models that indicate feature importance.\n",
            "\n",
            "4. **Building the Model:**\n",
            "   - **Linear Regression:** Fit a linear regression model to the data. Depending on feature relationships, you might want to explore polynomial regression or transformations (e.g., log transformation for price).\n",
            "   - **Train-Test Split:** Divide the dataset into training and testing sets (e.g., 70-30 split) to evaluate model performance.\n",
            "\n",
            "5. **Model Evaluation:**\n",
            "   - Assess the model using metrics like R-squared, Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE) on the test set.\n",
            "   - Use residual plots to check for homoscedasticity and linearity.\n",
            "\n",
            "6. **Tuning & Optimization:**\n",
            "   - Experiment with regularization techniques (e.g., Lasso, Ridge regression) to improve model performance.\n",
            "   - Consider cross-validation for more robust evaluation of model stability.\n",
            "\n",
            "### Implementation Example (Python Pseudocode)\n",
            "\n",
            "Here’s a basic pseudocode outline you might follow in Python:\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.linear_model import LinearRegression\n",
            "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
            "from sklearn.metrics import mean_squared_error, r2_score\n",
            "\n",
            "# Load dataset\n",
            "data = pd.read_csv('laptop_prices_2024_sgd_TL.csv')\n",
            "\n",
            "# Data Preprocessing\n",
            "data = data.dropna()  # Handle missing values\n",
            "data = pd.get_dummies(data, columns=['Brand', 'Model', 'CPU', 'GPU', 'Storage_Type'], drop_first=True)\n",
            "\n",
            "# Feature and target selection\n",
            "X = data.drop('Price_SGD', axis=1)  # Features\n",
            "y = data['Price_SGD']  # Target\n",
            "\n",
            "# Scaling\n",
            "scaler = StandardScaler()\n",
            "X_scaled = scaler.fit_transform(X)\n",
            "\n",
            "# Train-test split\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
            "\n",
            "# Model training\n",
            "model = LinearRegression()\n",
            "model.fit(X_train, y_train)\n",
            "\n",
            "# Predictions\n",
            "y_pred = model.predict(X_test)\n",
            "\n",
            "# Evaluation\n",
            "mse = mean_squared_error(y_test, y_pred)\n",
            "r2 = r2_score(y_test, y_pred)\n",
            "\n",
            "print(f'Mean Squared Error: {mse}')\n",
            "print(f'R-squared: {r2}')\n",
            "```\n",
            "\n",
            "### Conclusion\n",
            "Feel free to adjust the analysis depending on the insights derived from EDA or the performance of the initial models. Linear regression offers a foundation for predictive analysis, but you might consider more complex models depending on the accuracy required.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Brand,Model,CPU,GPU,RAM_GB,Storage_Type,Storage_GB,Touchscreen,Weight_kg,Screen_Size_inch,Discount_percent,Price_SGD,Brand_Discount,Member_Discount\n",
        "Acer,Aspire 5,Intel i9-14900HK,NVIDIA RTX 4070,64,SSD,256,False,1.56,16.0,3.27,2413.36,5,144.8\n",
        "Acer,Nitro 5,AMD Ryzen 9 8900HX,AMD Radeon 780M,32,SSD,1024,True,1.45,14.0,5.03,1773.75,5,124.16\n",
        "Acer,Nitro 5,AMD Ryzen 5 8600H,NVIDIA RTX 4050,32,SSD,2048,False,1.34,14.0,4.41,1634.07,5,98.04\n",
        "Acer,TravelMate P6,Intel Core Ultra 7 15500H,NVIDIA RTX 4060,16,SSD,4096,True,1.18,13.3,2.16,2362.59,5,118.13\n",
        "Acer,Predator Helios 300,Intel i7-14800H,NVIDIA RTX 4070,8,SSD,1024,True,1.31,14.0,6.93,2218.55,5,155.3\n",
        "Acer,Aspire 5,Intel i9-14900HK,NVIDIA RTX 4080,32,SSD,256,False,3.34,17.3,8.94,2224.12,5,155.69\n",
        "Acer,TravelMate P6,Intel i9-14900HK,NVIDIA RTX 4080,128,SSD,1024,True,1.11,13.3,11.72,3016.36,5,211.15\n",
        "Acer,Predator Helios 300,Intel Core Ultra 9 15700H,NVIDIA RTX 4070,16,SSD,2048,True,1.29,13.3,8.84,2579.29,5,180.55\n",
        "Acer,Swift 3,Intel i5-14500H,NVIDIA RTX 4050,64,SSD,4096,False,1.4,13.3,6.92,1976.94,5,98.85\n",
        "Acer,Nitro 5,Intel Core Ultra 9 15700H,NVIDIA RTX 4070,16,SSD,2048,False,1.15,13.3,5.25,2538.34,5,152.3\n",
        "\n",
        "Based on the dataset provided, let's explore key aspects for predictive analysis and linear regression. You have several features related to laptop specifications and pricing that can be useful for modeling.\n",
        "\n",
        "### Features Overview\n",
        "1. **Brand**\n",
        "2. **Model**\n",
        "3. **CPU**\n",
        "4. **GPU**\n",
        "5. **RAM_GB**\n",
        "6. **Storage_Type**\n",
        "7. **Storage_GB**\n",
        "8. **Touchscreen** (boolean)\n",
        "9. **Weight_kg**\n",
        "10. **Screen_Size_inch**\n",
        "11. **Discount_percent**\n",
        "12. **Price_SGD**\n",
        "13. **Brand_Discount**\n",
        "14. **Member_Discount**\n",
        "\n",
        "### Steps for Analysis\n",
        "\n",
        "1. **Data Preprocessing:**\n",
        "   - **Encoding Categorical Variables:** Convert categorical features like `Brand`, `Model`, `CPU`, `GPU`, and `Storage_Type` into numerical form using techniques like one-hot encoding or label encoding.\n",
        "   - **Handling Missing Values:** Check for any missing values and decide how to handle them (e.g., imputation, removal).\n",
        "   - **Normalizing/Standardizing Numerical Features:** Apply scaling to the features, especially those that vary in magnitude, such as `Weight_kg`, `Screen_Size_inch`, and `Price_SGD`.\n",
        "\n",
        "2. **Exploratory Data Analysis (EDA):**\n",
        "   - **Correlation Analysis:** Use correlation matrices to understand relationships between features and the target variable (`Price_SGD`).\n",
        "   - **Visualizations:** Create scatter plots, box plots, and histograms to visualize the distribution of laptop prices and other features.\n",
        "\n",
        "3. **Feature Selection:**\n",
        "   - Assess which features are most influential for predicting laptop prices. This may involve using techniques such as recursive feature elimination or considering models that indicate feature importance.\n",
        "\n",
        "4. **Building the Model:**\n",
        "   - **Linear Regression:** Fit a linear regression model to the data. Depending on feature relationships, you might want to explore polynomial regression or transformations (e.g., log transformation for price).\n",
        "   - **Train-Test Split:** Divide the dataset into training and testing sets (e.g., 70-30 split) to evaluate model performance.\n",
        "\n",
        "5. **Model Evaluation:**\n",
        "   - Assess the model using metrics like R-squared, Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE) on the test set.\n",
        "   - Use residual plots to check for homoscedasticity and linearity.\n",
        "\n",
        "6. **Tuning & Optimization:**\n",
        "   - Experiment with regularization techniques (e.g., Lasso, Ridge regression) to improve model performance.\n",
        "   - Consider cross-validation for more robust evaluation of model stability.\n",
        "\n",
        "### Implementation Example (Python Pseudocode)\n",
        "\n",
        "Here’s a basic pseudocode outline you might follow in Python:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('laptop_prices_2024_sgd_TL.csv')\n",
        "\n",
        "# Data Preprocessing\n",
        "data = data.dropna()  # Handle missing values\n",
        "data = pd.get_dummies(data, columns=['Brand', 'Model', 'CPU', 'GPU', 'Storage_Type'], drop_first=True)\n",
        "\n",
        "# Feature and target selection\n",
        "X = data.drop('Price_SGD', axis=1)  # Features\n",
        "y = data['Price_SGD']  # Target\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Model training\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R-squared: {r2}')\n",
        "```\n",
        "\n",
        "### Conclusion\n",
        "Feel free to adjust the analysis depending on the insights derived from EDA or the performance of the initial models. Linear regression offers a foundation for predictive analysis, but you might consider more complex models depending on the accuracy required."
      ],
      "metadata": {
        "id": "jrGPJyF1g9KL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What parts of the code from APREP are specific to the dataset?\n",
        "Answer: \"input\" code.\n",
        "\n",
        "What parts needs to be modified to adapt to the new dataset?\n",
        "Answer:You need a code to read a dataset from specific directory where its saved.\n",
        "\n",
        "Is there a way to make it generic and adaptable to any new dataset?\n",
        "Answer. A function call below\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def load_dataset(path, target_col=None):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NUYXh60Qh4e1"
      }
    }
  ]
}