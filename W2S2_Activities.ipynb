{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLcp/JUfaSzbPbjfHQ9ACI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jhonald73/TPproj_github/blob/main/W2S2_Activities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDVt9kkIde3T",
        "outputId": "7b427185-65a4-448f-a70e-113d4b09f8cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from openai import OpenAI\n"
      ],
      "metadata": {
        "id": "kqSxZ2KNdoce"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "# Load key from Google Colab Secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=api_key,\n",
        ")"
      ],
      "metadata": {
        "id": "Eb2TU_2OdqLr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Automated Data Prep/laptop_prices_2024_sgd_TL.csv\")"
      ],
      "metadata": {
        "id": "H4RJ9Uj4d27Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the first few rows to a string to send to OpenAI\n",
        "data_preview = df.head(10).to_csv(index=False)\n",
        "print(data_preview)\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    instructions=\"You are an expert data scientist with extensive knowledge of predictive analysis and linear regression.\",\n",
        "    input=f\"Dataset: Iris flower classification (150 samples, 4 features, 3 classes)\\nHere are the first 10 rows of the dataset:\\n{data_preview}]\",\n",
        ")\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2hDCB3LeiD_",
        "outputId": "dfa41c10-3717-4f40-98d5-9ec3f1f6f835"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brand,Model,CPU,GPU,RAM_GB,Storage_Type,Storage_GB,Touchscreen,Weight_kg,Screen_Size_inch,Discount_percent,Price_SGD,Brand_Discount,Member_Discount\n",
            "Acer,Aspire 5,Intel i9-14900HK,NVIDIA RTX 4070,64,SSD,256,False,1.56,16.0,3.27,2413.36,5,144.8\n",
            "Acer,Nitro 5,AMD Ryzen 9 8900HX,AMD Radeon 780M,32,SSD,1024,True,1.45,14.0,5.03,1773.75,5,124.16\n",
            "Acer,Nitro 5,AMD Ryzen 5 8600H,NVIDIA RTX 4050,32,SSD,2048,False,1.34,14.0,4.41,1634.07,5,98.04\n",
            "Acer,TravelMate P6,Intel Core Ultra 7 15500H,NVIDIA RTX 4060,16,SSD,4096,True,1.18,13.3,2.16,2362.59,5,118.13\n",
            "Acer,Predator Helios 300,Intel i7-14800H,NVIDIA RTX 4070,8,SSD,1024,True,1.31,14.0,6.93,2218.55,5,155.3\n",
            "Acer,Aspire 5,Intel i9-14900HK,NVIDIA RTX 4080,32,SSD,256,False,3.34,17.3,8.94,2224.12,5,155.69\n",
            "Acer,TravelMate P6,Intel i9-14900HK,NVIDIA RTX 4080,128,SSD,1024,True,1.11,13.3,11.72,3016.36,5,211.15\n",
            "Acer,Predator Helios 300,Intel Core Ultra 9 15700H,NVIDIA RTX 4070,16,SSD,2048,True,1.29,13.3,8.84,2579.29,5,180.55\n",
            "Acer,Swift 3,Intel i5-14500H,NVIDIA RTX 4050,64,SSD,4096,False,1.4,13.3,6.92,1976.94,5,98.85\n",
            "Acer,Nitro 5,Intel Core Ultra 9 15700H,NVIDIA RTX 4070,16,SSD,2048,False,1.15,13.3,5.25,2538.34,5,152.3\n",
            "\n",
            "It looks like you are working with a dataset related to laptop specifications and prices, rather than the Iris flower dataset. This dataset has features such as CPU, GPU, RAM, storage type, weight, screen size, discounts, and price. Given this data, you can perform several types of analysis, including:\n",
            "\n",
            "### Potential Analyses\n",
            "\n",
            "1. **Predictive Modeling**: You can use linear regression or other models to predict laptop prices based on features like RAM, weight, and screen size.\n",
            "\n",
            "2. **Feature Importance Analysis**: You can evaluate which features are most influential in determining the price.\n",
            "\n",
            "3. **Comparative Analytics**: Compare average prices across different brands or categories (e.g., CPU or GPU types).\n",
            "\n",
            "4. **Discount Effectiveness**: Analyze how discounts affect the final selling price and if certain models benefit more from discounts than others.\n",
            "\n",
            "### Steps to Perform Linear Regression:\n",
            "\n",
            "1. **Data Preprocessing**:\n",
            "   - Convert categorical variables (e.g., Brand, Storage_Type) into numerical formats using one-hot encoding.\n",
            "   - Handle missing values if any.\n",
            "   - Normalize or scale the numerical features if necessary.\n",
            "\n",
            "2. **Feature Selection**:\n",
            "   - Choose relevant features for predicting price (e.g., CPU, GPU, RAM_GB, Weight_kg, etc.).\n",
            "\n",
            "3. **Splitting Data**:\n",
            "   - Split the dataset into training and testing subsets (e.g., 80% training, 20% testing).\n",
            "\n",
            "4. **Model Building**:\n",
            "   - Fit a linear regression model using the training data.\n",
            "\n",
            "5. **Model Evaluation**:\n",
            "   - Assess the model's performance using metrics like R² and RMSE on the test set.\n",
            "\n",
            "6. **Interpret Results and Make Predictions**:\n",
            "   - Analyze coefficients to understand the relationship between features and the price.\n",
            "   - Use the model to make price predictions for new laptop configurations.\n",
            "\n",
            "### Example Code Snippet in Python:\n",
            "\n",
            "Here’s an example of how you might implement this using Python with libraries such as pandas and scikit-learn:\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.linear_model import LinearRegression\n",
            "from sklearn.metrics import mean_squared_error, r2_score\n",
            "\n",
            "# Load the dataset\n",
            "data = pd.read_csv('laptops.csv')\n",
            "\n",
            "# Preprocessing: one-hot encode categorical variables\n",
            "data_processed = pd.get_dummies(data, columns=['Brand', 'Storage_Type'], drop_first=True)\n",
            "\n",
            "# Features and target variable\n",
            "X = data_processed.drop('Price_SGD', axis=1)\n",
            "y = data_processed['Price_SGD']\n",
            "\n",
            "# Split the data\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
            "\n",
            "# Model building\n",
            "model = LinearRegression()\n",
            "model.fit(X_train, y_train)\n",
            "\n",
            "# Predictions\n",
            "y_pred = model.predict(X_test)\n",
            "\n",
            "# Evaluation\n",
            "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
            "print(\"R² Score:\", r2_score(y_test, y_pred))\n",
            "\n",
            "# Coefficients\n",
            "coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\n",
            "print(coefficients)\n",
            "```\n",
            "\n",
            "### Next Steps\n",
            "\n",
            "1. Explore interactions between features.\n",
            "2. Consider other models (e.g., Random Forest, Gradient Boosting) for potentially better performance.\n",
            "3. Visualizations can help understand relationships and distributions in the data.\n",
            "\n",
            "Feel free to ask specific questions about any of these analyses, and I can provide further guidance!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_8wT6nzDehwk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}